% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/glasp_regression.R
\name{glasp_regression}
\alias{glasp_regression}
\title{parsnip interface for GLASP - Regression Models}
\usage{
glasp_regression(
  mode = "regression",
  l1 = NULL,
  l2 = NULL,
  frob = NULL,
  num_comp = NULL
)
}
\arguments{
\item{mode}{A single character string for the type of model.}

\item{l1}{Regularization in norm l1 (lasso)}

\item{l2}{Regularization in norm l2 (ridge)}

\item{frob}{Regularization in Frobenius norm. It is unique to glasp and controls the importance
of the clustering on the variables. If frob=0, we want to fit a model equivalent to elastic-net,
without clustering. If frob > l1+l2 means that we are more interested on the feature clustering
than the variable selection. If frob > 1 we are more interested on finding clusters than on
getting a linear model with good predictive power.}

\item{num_comp}{Maximum number of clusters to search.}
}
\value{
A \code{glasp_regression} parsnip model
}
\description{
parsnip interface for GLASP - Regression Models
}
\examples{

library(parsnip)
library(yardstick)

set.seed(0)
data <- simulate_dummy_linear_data()

model <- glasp_regression(l1 = 0.05, l2 = 0.01, frob = 0.001, num_comp = 3) \%>\%
  set_engine("glasp") \%>\%
  fit(y~., data)

pred = predict(model$fit, data, type="numeric")
rmse = rmse_vec(data$y, pred)

#--- with tune ----
\dontrun{
library(parsnip)
library(tune)
library(yardstick)
library(rsample)

set.seed(0)
data <- simulate_dummy_linear_data()

model <- glasp_regression(l1 = tune(), l2 = tune(), frob = tune(), num_comp = tune()) \%>\%
set_engine("glasp")

data_rs <- vfold_cv(data, v = 4)
hist <- tune_grid(model, y~.,
        resamples = data_rs,
        metrics = metric_set(rmse),
        grid = 100,
        control = control_grid(verbose = T, save_pred = T))
show_best(hist, 'rmse')
}

}
